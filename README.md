# Variational Autoencoder (VAE) for Modified National Institute of Standards and Technology database (MNIST)
Variational AutoEncoders (VAEs) are a sophisticated type of generative model that can learn to represent and produce data by encoding it into a latent space and then decoding it back into the 
original space. For more information you can read this paper by [Kingma and Welling](https://arxiv.org/abs/1906.02691). In this project I have trained a VAE for generating MNIST digits. 
## Running the code
Open the [vae-for-mnist notebook](https://github.com/prachitui/VAE-for-Modified-National-Institute-of-Standards-and-Technology-database/blob/main/vae-for-mnist.ipynb) and run the cells 
sequentially. The code was run on Kaggle. You can also download the notebook and run it on Google Colab or on Jupyter Notebook.
